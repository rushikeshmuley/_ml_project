{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "\nXGBoost Library (xgboost.dll) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed\n    - vcomp140.dll or libgomp-1.dll for Windows\n    - libomp.dylib for Mac OSX\n    - libgomp.so for Linux and other UNIX-like OSes\n    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n\n  * You are running 32-bit Python on a 64-bit OS\n\nError message(s): ['[WinError 8] Not enough memory resources are available to process this command']\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m RandomizedSearchCV\n\u001b[0;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcatboost\u001b[39;00m \u001b[39mimport\u001b[39;00m CatBoostRegressor\n\u001b[1;32m---> 16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mxgboost\u001b[39;00m \u001b[39mimport\u001b[39;00m XGBRegressor\n\u001b[0;32m     17\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rushi\\OneDrive\\Desktop\\machine learning project\\venv\\lib\\site-packages\\xgboost\\__init__.py:7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m\"\"\"XGBoost: eXtreme Gradient Boosting library.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[39mContributors: https://github.com/dmlc/xgboost/blob/master/CONTRIBUTORS.md\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m tracker  \u001b[39m# noqa\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m collective, dask, rabit\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      9\u001b[0m     Booster,\n\u001b[0;32m     10\u001b[0m     DataIter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m     build_info,\n\u001b[0;32m     16\u001b[0m )\n\u001b[0;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtracker\u001b[39;00m \u001b[39mimport\u001b[39;00m RabitTracker  \u001b[39m# noqa\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rushi\\OneDrive\\Desktop\\machine learning project\\venv\\lib\\site-packages\\xgboost\\collective.py:12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_typing\u001b[39;00m \u001b[39mimport\u001b[39;00m _T\n\u001b[1;32m---> 12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m _LIB, _check_call, c_str, py_str, from_pystr_to_cstr\n\u001b[0;32m     14\u001b[0m LOGGER \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mgetLogger(\u001b[39m\"\u001b[39m\u001b[39m[xgboost.collective]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minit\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39margs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\rushi\\OneDrive\\Desktop\\machine learning project\\venv\\lib\\site-packages\\xgboost\\core.py:264\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\n\u001b[0;32m    263\u001b[0m \u001b[39m# load the XGBoost library globally\u001b[39;00m\n\u001b[1;32m--> 264\u001b[0m _LIB \u001b[39m=\u001b[39m _load_lib()\n\u001b[0;32m    267\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_call\u001b[39m(ret: \u001b[39mint\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    268\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[0;32m    269\u001b[0m \n\u001b[0;32m    270\u001b[0m \u001b[39m    This function will raise exception when error occurs.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[39m        return value from API calls\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rushi\\OneDrive\\Desktop\\machine learning project\\venv\\lib\\site-packages\\xgboost\\core.py:216\u001b[0m, in \u001b[0;36m_load_lib\u001b[1;34m()\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m lib_success:\n\u001b[0;32m    215\u001b[0m         libname \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(lib_paths[\u001b[39m0\u001b[39m])\n\u001b[1;32m--> 216\u001b[0m         \u001b[39mraise\u001b[39;00m XGBoostError(\n\u001b[0;32m    217\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m    218\u001b[0m \u001b[39mXGBoost Library (\u001b[39m\u001b[39m{\u001b[39;00mlibname\u001b[39m}\u001b[39;00m\u001b[39m) could not be loaded.\u001b[39m\n\u001b[0;32m    219\u001b[0m \u001b[39mLikely causes:\u001b[39m\n\u001b[0;32m    220\u001b[0m \u001b[39m  * OpenMP runtime is not installed\u001b[39m\n\u001b[0;32m    221\u001b[0m \u001b[39m    - vcomp140.dll or libgomp-1.dll for Windows\u001b[39m\n\u001b[0;32m    222\u001b[0m \u001b[39m    - libomp.dylib for Mac OSX\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39m    - libgomp.so for Linux and other UNIX-like OSes\u001b[39m\n\u001b[0;32m    224\u001b[0m \u001b[39m    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\u001b[39m\n\u001b[0;32m    225\u001b[0m \n\u001b[0;32m    226\u001b[0m \u001b[39m  * You are running 32-bit Python on a 64-bit OS\u001b[39m\n\u001b[0;32m    227\u001b[0m \n\u001b[0;32m    228\u001b[0m \u001b[39mError message(s): \u001b[39m\u001b[39m{\u001b[39;00mos_error_list\u001b[39m}\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m    230\u001b[0m         )\n\u001b[0;32m    231\u001b[0m     lib\u001b[39m.\u001b[39mXGBGetLastError\u001b[39m.\u001b[39mrestype \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_char_p\n\u001b[0;32m    232\u001b[0m     lib\u001b[39m.\u001b[39mcallback \u001b[39m=\u001b[39m _get_log_callback_func()  \u001b[39m# type: ignore\u001b[39;00m\n",
      "\u001b[1;31mXGBoostError\u001b[0m: \nXGBoost Library (xgboost.dll) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed\n    - vcomp140.dll or libgomp-1.dll for Windows\n    - libomp.dylib for Mac OSX\n    - libgomp.so for Linux and other UNIX-like OSes\n    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n\n  * You are running 32-bit Python on a 64-bit OS\n\nError message(s): ['[WinError 8] Not enough memory resources are available to process this command']\n"
     ]
    }
   ],
   "source": [
    "# Basic Import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "# Modelling\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression, Ridge,Lasso\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/stud.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['math_score'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Categories in 'gender' variable:     \",end=\" \" )\n",
    "print(df['gender'].unique())\n",
    "\n",
    "print(\"Categories in 'race_ethnicity' variable:  \",end=\" \")\n",
    "print(df['race_ethnicity'].unique())\n",
    "\n",
    "print(\"Categories in'parental level of education' variable:\",end=\" \" )\n",
    "print(df['parental_level_of_education'].unique())\n",
    "\n",
    "print(\"Categories in 'lunch' variable:     \",end=\" \" )\n",
    "print(df['lunch'].unique())\n",
    "\n",
    "print(\"Categories in 'test preparation course' variable:     \",end=\" \" )\n",
    "print(df['test_preparation_course'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['math_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Column Transformer with 3 types of transformers\n",
    "num_features = X.select_dtypes(exclude=\"object\").columns\n",
    "cat_features = X.select_dtypes(include=\"object\").columns\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "oh_transformer = OneHotEncoder()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"OneHotEncoder\", oh_transformer, cat_features),\n",
    "         (\"StandardScaler\", numeric_transformer, num_features),        \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(true, predicted):\n",
    "    mae = mean_absolute_error(true, predicted)\n",
    "    mse = mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(mean_squared_error(true, predicted))\n",
    "    r2_square = r2_score(true, predicted)\n",
    "    return mae, rmse, r2_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"K-Neighbors Regressor\": KNeighborsRegressor(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(),\n",
    "    \"XGBRegressor\": XGBRegressor(), \n",
    "    \"CatBoosting Regressor\": CatBoostRegressor(verbose=False),\n",
    "    \"AdaBoost Regressor\": AdaBoostRegressor()\n",
    "}\n",
    "model_list = []\n",
    "r2_list =[]\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train, y_train) # Train model\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate Train and Test dataset\n",
    "    model_train_mae , model_train_rmse, model_train_r2 = evaluate_model(y_train, y_train_pred)\n",
    "\n",
    "    model_test_mae , model_test_rmse, model_test_r2 = evaluate_model(y_test, y_test_pred)\n",
    "\n",
    "    \n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_train_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_train_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_train_r2))\n",
    "\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_test_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_test_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_test_r2))\n",
    "    r2_list.append(model_test_r2)\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(list(zip(model_list, r2_list)), columns=['Model Name', 'R2_Score']).sort_values(by=[\"R2_Score\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_model = LinearRegression(fit_intercept=True)\n",
    "lin_model = lin_model.fit(X_train, y_train)\n",
    "y_pred = lin_model.predict(X_test)\n",
    "score = r2_score(y_test, y_pred)*100\n",
    "print(\" Accuracy of the model is %.2f\" %score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test,y_pred);\n",
    "plt.xlabel('Actual');\n",
    "plt.ylabel('Predicted');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=y_test,y=y_pred,ci=None,color ='red');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df=pd.DataFrame({'Actual Value':y_test,'Predicted Value':y_pred,'Difference':y_test-y_pred})\n",
    "pred_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
